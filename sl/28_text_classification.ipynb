{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krakowiakpawel9/ml_course/blob/master/sl/28_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbjsT92Xd3z1",
        "colab_type": "text"
      },
      "source": [
        "### scikit-learn\n",
        "Strona biblioteki: [https://scikit-learn.org](https://scikit-learn.org)  \n",
        "\n",
        "Dokumentacja/User Guide: [https://scikit-learn.org/stable/user_guide.html](https://scikit-learn.org/stable/user_guide.html)\n",
        "\n",
        "Podstawowa biblioteka do uczenia maszynowego w języku Python.\n",
        "\n",
        "Aby zainstalować bibliotekę scikit-learn, użyj polecenia poniżej:\n",
        "```\n",
        "!pip install scikit-learn\n",
        "```\n",
        "Aby zaktualizować do najnowszej wersji bibliotekę scikit-learn, użyj polecenia poniżej:\n",
        "```\n",
        "!pip install --upgrade scikit-learn\n",
        "```\n",
        "Kurs stworzony w oparciu o wersję `0.22.1`\n",
        "\n",
        "### Preprocessing danych:\n",
        "1. [Import bibliotek](#0)\n",
        "2. [Wygenerowanie danych](#1)\n",
        "3. [Utworzenie kopii danych](#2)\n",
        "4. [Zmiana typu danych i wstępna eksploracja](#3)\n",
        "5. [LabelEncoder](#4)\n",
        "6. [OneHotEncoder](#5)\n",
        "7. [Pandas *get_dummies()*](#6)\n",
        "8. [Standaryzacja - StandardScaler](#7)\n",
        "9. [Przygotowanie danych do modelu](#8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkIALacsUnj7",
        "colab_type": "text"
      },
      "source": [
        "### <a name='0'></a> Import bibliotek"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ0ieU0UdN5D",
        "colab_type": "code",
        "outputId": "edbc2a4c-e6b9-42d0-fac9-5f47f8d42cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import sklearn\n",
        "\n",
        "np.random.seed(42)\n",
        "np.set_printoptions(precision=6, suppress=True, edgeitems=10, linewidth=1000, formatter=dict(float=lambda x: f'{x:.2f}'))\n",
        "sklearn.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.22.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBpPTM0_G1g0",
        "colab_type": "text"
      },
      "source": [
        "Ekstrakcja cech z tekstu  \n",
        "unigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIvE08DvwHyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KrM9_ZkHnum",
        "colab_type": "code",
        "outputId": "e1007ae2-4f4a-4b0c-ed54-9c471e38aa38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ne-0zWHHsil",
        "colab_type": "code",
        "outputId": "542d9e39-ff91-45c7-d36b-39dde6a510f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "corpus = [\n",
        "    'Today is Friday',\n",
        "    'I like Friday',\n",
        "    'Today I am going to learn Python.',\n",
        "    'Friday, Friday!!!'\n",
        "]\n",
        "\n",
        "vectorizer.fit_transform(corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 12 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvdVvqmtIJnN",
        "colab_type": "code",
        "outputId": "6dda9cf7-43a8-4eda-a483-924a7c84d733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "vectorizer.fit_transform(corpus).toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 1, 0, 0, 0, 0, 1],\n",
              "       [0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
              "       [0, 2, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyRa3cnUIQAU",
        "colab_type": "code",
        "outputId": "8ed79f84-7f67-4dda-9663-e83cd9da2b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vectorizer.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['am', 'friday', 'going', 'is', 'learn', 'like', 'python', 'to', 'today']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na4F6cMVIdOW",
        "colab_type": "code",
        "outputId": "441a5ed5-68f1-4249-dd7c-d583538d51af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "df = pd.DataFrame(data=vectorizer.fit_transform(corpus).toarray(), columns=vectorizer.get_feature_names())\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>am</th>\n",
              "      <th>friday</th>\n",
              "      <th>going</th>\n",
              "      <th>is</th>\n",
              "      <th>learn</th>\n",
              "      <th>like</th>\n",
              "      <th>python</th>\n",
              "      <th>to</th>\n",
              "      <th>today</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   am  friday  going  is  learn  like  python  to  today\n",
              "0   0       1      0   1      0     0       0   0      1\n",
              "1   0       1      0   0      0     1       0   0      0\n",
              "2   1       0      1   0      1     0       1   1      1\n",
              "3   0       2      0   0      0     0       0   0      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqjXiS0_Ir71",
        "colab_type": "code",
        "outputId": "b162bc1e-b11c-457e-80e3-7ee36158ce3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "df.describe().T"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>am</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>friday</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.816497</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>going</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>learn</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>like</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>python</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>today</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        count  mean       std  min   25%  50%   75%  max\n",
              "am        4.0  0.25  0.500000  0.0  0.00  0.0  0.25  1.0\n",
              "friday    4.0  1.00  0.816497  0.0  0.75  1.0  1.25  2.0\n",
              "going     4.0  0.25  0.500000  0.0  0.00  0.0  0.25  1.0\n",
              "is        4.0  0.25  0.500000  0.0  0.00  0.0  0.25  1.0\n",
              "learn     4.0  0.25  0.500000  0.0  0.00  0.0  0.25  1.0\n",
              "like      4.0  0.25  0.500000  0.0  0.00  0.0  0.25  1.0\n",
              "python    4.0  0.25  0.500000  0.0  0.00  0.0  0.25  1.0\n",
              "to        4.0  0.25  0.500000  0.0  0.00  0.0  0.25  1.0\n",
              "today     4.0  0.50  0.577350  0.0  0.00  0.5  1.00  1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ficlSsBHJDHQ",
        "colab_type": "code",
        "outputId": "71c4b801-745e-4bbb-e63c-94c7ac9e3b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4 entries, 0 to 3\n",
            "Data columns (total 9 columns):\n",
            "am        4 non-null int64\n",
            "friday    4 non-null int64\n",
            "going     4 non-null int64\n",
            "is        4 non-null int64\n",
            "learn     4 non-null int64\n",
            "like      4 non-null int64\n",
            "python    4 non-null int64\n",
            "to        4 non-null int64\n",
            "today     4 non-null int64\n",
            "dtypes: int64(9)\n",
            "memory usage: 416.0 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzqY6_poJKO_",
        "colab_type": "code",
        "outputId": "53cff1b7-43d8-4d6e-ef2e-40b62207214c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "vectorizer.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'am': 0,\n",
              " 'friday': 1,\n",
              " 'going': 2,\n",
              " 'is': 3,\n",
              " 'learn': 4,\n",
              " 'like': 5,\n",
              " 'python': 6,\n",
              " 'to': 7,\n",
              " 'today': 8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39Z6dORBJTXa",
        "colab_type": "code",
        "outputId": "7c063906-55a0-4048-f906-80b5d2e6a6a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vectorizer.transform(['Friday morning']).toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYIxfKIBJkX9",
        "colab_type": "code",
        "outputId": "5b71d2ce-89a5-4cba-de27-14b4d0563f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "bigram = CountVectorizer(ngram_range=(1, 2), min_df=1)    # min_df=2\n",
        "bigram.fit_transform(corpus).toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0],\n",
              "       [0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4LEASm4Kb0Z",
        "colab_type": "code",
        "outputId": "9fc0c688-8aca-43dc-d93c-b6cf875146e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "bigram.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'am': 0,\n",
              " 'am going': 1,\n",
              " 'friday': 2,\n",
              " 'friday friday': 3,\n",
              " 'going': 4,\n",
              " 'going to': 5,\n",
              " 'is': 6,\n",
              " 'is friday': 7,\n",
              " 'learn': 8,\n",
              " 'learn python': 9,\n",
              " 'like': 10,\n",
              " 'like friday': 11,\n",
              " 'python': 12,\n",
              " 'to': 13,\n",
              " 'to learn': 14,\n",
              " 'today': 15,\n",
              " 'today am': 16,\n",
              " 'today is': 17}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvv32H_1KeHS",
        "colab_type": "code",
        "outputId": "449a3257-68c0-43fc-bf2a-7e8563e13646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "df = pd.DataFrame(data=bigram.fit_transform(corpus).toarray(), columns=bigram.get_feature_names())\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>am</th>\n",
              "      <th>am going</th>\n",
              "      <th>friday</th>\n",
              "      <th>friday friday</th>\n",
              "      <th>going</th>\n",
              "      <th>going to</th>\n",
              "      <th>is</th>\n",
              "      <th>is friday</th>\n",
              "      <th>learn</th>\n",
              "      <th>learn python</th>\n",
              "      <th>like</th>\n",
              "      <th>like friday</th>\n",
              "      <th>python</th>\n",
              "      <th>to</th>\n",
              "      <th>to learn</th>\n",
              "      <th>today</th>\n",
              "      <th>today am</th>\n",
              "      <th>today is</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   am  am going  friday  friday friday  ...  to learn  today  today am  today is\n",
              "0   0         0       1              0  ...         0      1         0         1\n",
              "1   0         0       1              0  ...         0      0         0         0\n",
              "2   1         1       0              0  ...         1      1         1         0\n",
              "3   0         0       2              1  ...         0      0         0         0\n",
              "\n",
              "[4 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY5hnu_cL0j5",
        "colab_type": "text"
      },
      "source": [
        "TF-IDF Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGRe6KMtKhZ1",
        "colab_type": "code",
        "outputId": "3e4b473d-aae8-4992-de4c-1d93346cd592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf = TfidfTransformer()\n",
        "tfidf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjbS9fqoMSsR",
        "colab_type": "code",
        "outputId": "2892af0a-8af2-4a6c-c619-d66df15d39b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "corpus = [\n",
        "    'Friday morning',\n",
        "    'Friday chill',\n",
        "    'Friday - morning',\n",
        "    'Friday, Friday morning!!!'\n",
        "]\n",
        "\n",
        "counts = vectorizer.fit_transform(corpus).toarray()\n",
        "counts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1],\n",
              "       [1, 1, 0],\n",
              "       [0, 1, 1],\n",
              "       [0, 2, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IITljFK_M1sy",
        "colab_type": "code",
        "outputId": "5b99e141-cb2f-4e47-98a5-ed1441afb3ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "df = pd.DataFrame(data=vectorizer.fit_transform(corpus).toarray(), columns=vectorizer.get_feature_names())\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chill</th>\n",
              "      <th>friday</th>\n",
              "      <th>morning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   chill  friday  morning\n",
              "0      0       1        1\n",
              "1      1       1        0\n",
              "2      0       1        1\n",
              "3      0       2        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev9wZwGwM_xL",
        "colab_type": "code",
        "outputId": "b0e06324-52a2-4dcb-a596-a7f7dcfbd509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "tfidf.fit_transform(counts).toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.63295194, 0.77419109],\n",
              "       [0.88654763, 0.46263733, 0.        ],\n",
              "       [0.        , 0.63295194, 0.77419109],\n",
              "       [0.        , 0.85310692, 0.52173612]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP3Uv5xUOR85",
        "colab_type": "text"
      },
      "source": [
        "TF-IDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRWPRKenNK85",
        "colab_type": "code",
        "outputId": "c92cd1ce-58c7-406c-b4dd-5218ed6e717c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectorizer.fit_transform(corpus).toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.63295194, 0.77419109],\n",
              "       [0.88654763, 0.46263733, 0.        ],\n",
              "       [0.        , 0.63295194, 0.77419109],\n",
              "       [0.        , 0.85310692, 0.52173612]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_ig2UjGOAzq",
        "colab_type": "code",
        "outputId": "241d1c9d-f2e6-4d66-dbef-d4050b9346a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tfidf_vectorizer.idf_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.91629073, 1.        , 1.22314355])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4uAUh5wOVzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCReaOB7PpKj",
        "colab_type": "code",
        "outputId": "27b8e4f2-495f-4a91-ffb3-442997b0f75b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "raw_data = fetch_20newsgroups(subset='train', categories=['comp.graphics'], random_state=42)\n",
        "raw_data.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4otp857P5P5",
        "colab_type": "code",
        "outputId": "80245b1d-adca-44a8-b5bc-4231ded3b5bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "all_data = raw_data.copy()\n",
        "print(all_data['DESCR'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _20newsgroups_dataset:\n",
            "\n",
            "The 20 newsgroups text dataset\n",
            "------------------------------\n",
            "\n",
            "The 20 newsgroups dataset comprises around 18000 newsgroups posts on\n",
            "20 topics split in two subsets: one for training (or development)\n",
            "and the other one for testing (or for performance evaluation). The split\n",
            "between the train and test set is based upon a messages posted before\n",
            "and after a specific date.\n",
            "\n",
            "This module contains two loaders. The first one,\n",
            ":func:`sklearn.datasets.fetch_20newsgroups`,\n",
            "returns a list of the raw texts that can be fed to text feature\n",
            "extractors such as :class:`sklearn.feature_extraction.text.CountVectorizer`\n",
            "with custom parameters so as to extract feature vectors.\n",
            "The second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\n",
            "returns ready-to-use features, i.e., it is not necessary to use a feature\n",
            "extractor.\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    =================   ==========\n",
            "    Classes                     20\n",
            "    Samples total            18846\n",
            "    Dimensionality               1\n",
            "    Features                  text\n",
            "    =================   ==========\n",
            "\n",
            "Usage\n",
            "~~~~~\n",
            "\n",
            "The :func:`sklearn.datasets.fetch_20newsgroups` function is a data\n",
            "fetching / caching functions that downloads the data archive from\n",
            "the original `20 newsgroups website`_, extracts the archive contents\n",
            "in the ``~/scikit_learn_data/20news_home`` folder and calls the\n",
            ":func:`sklearn.datasets.load_files` on either the training or\n",
            "testing set folder, or both of them::\n",
            "\n",
            "  >>> from sklearn.datasets import fetch_20newsgroups\n",
            "  >>> newsgroups_train = fetch_20newsgroups(subset='train')\n",
            "\n",
            "  >>> from pprint import pprint\n",
            "  >>> pprint(list(newsgroups_train.target_names))\n",
            "  ['alt.atheism',\n",
            "   'comp.graphics',\n",
            "   'comp.os.ms-windows.misc',\n",
            "   'comp.sys.ibm.pc.hardware',\n",
            "   'comp.sys.mac.hardware',\n",
            "   'comp.windows.x',\n",
            "   'misc.forsale',\n",
            "   'rec.autos',\n",
            "   'rec.motorcycles',\n",
            "   'rec.sport.baseball',\n",
            "   'rec.sport.hockey',\n",
            "   'sci.crypt',\n",
            "   'sci.electronics',\n",
            "   'sci.med',\n",
            "   'sci.space',\n",
            "   'soc.religion.christian',\n",
            "   'talk.politics.guns',\n",
            "   'talk.politics.mideast',\n",
            "   'talk.politics.misc',\n",
            "   'talk.religion.misc']\n",
            "\n",
            "The real data lies in the ``filenames`` and ``target`` attributes. The target\n",
            "attribute is the integer index of the category::\n",
            "\n",
            "  >>> newsgroups_train.filenames.shape\n",
            "  (11314,)\n",
            "  >>> newsgroups_train.target.shape\n",
            "  (11314,)\n",
            "  >>> newsgroups_train.target[:10]\n",
            "  array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])\n",
            "\n",
            "It is possible to load only a sub-selection of the categories by passing the\n",
            "list of the categories to load to the\n",
            ":func:`sklearn.datasets.fetch_20newsgroups` function::\n",
            "\n",
            "  >>> cats = ['alt.atheism', 'sci.space']\n",
            "  >>> newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
            "\n",
            "  >>> list(newsgroups_train.target_names)\n",
            "  ['alt.atheism', 'sci.space']\n",
            "  >>> newsgroups_train.filenames.shape\n",
            "  (1073,)\n",
            "  >>> newsgroups_train.target.shape\n",
            "  (1073,)\n",
            "  >>> newsgroups_train.target[:10]\n",
            "  array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
            "\n",
            "Converting text to vectors\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "In order to feed predictive or clustering models with the text data,\n",
            "one first need to turn the text into vectors of numerical values suitable\n",
            "for statistical analysis. This can be achieved with the utilities of the\n",
            "``sklearn.feature_extraction.text`` as demonstrated in the following\n",
            "example that extract `TF-IDF`_ vectors of unigram tokens\n",
            "from a subset of 20news::\n",
            "\n",
            "  >>> from sklearn.feature_extraction.text import TfidfVectorizer\n",
            "  >>> categories = ['alt.atheism', 'talk.religion.misc',\n",
            "  ...               'comp.graphics', 'sci.space']\n",
            "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
            "  ...                                       categories=categories)\n",
            "  >>> vectorizer = TfidfVectorizer()\n",
            "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
            "  >>> vectors.shape\n",
            "  (2034, 34118)\n",
            "\n",
            "The extracted TF-IDF vectors are very sparse, with an average of 159 non-zero\n",
            "components by sample in a more than 30000-dimensional space\n",
            "(less than .5% non-zero features)::\n",
            "\n",
            "  >>> vectors.nnz / float(vectors.shape[0])\n",
            "  159.01327...\n",
            "\n",
            ":func:`sklearn.datasets.fetch_20newsgroups_vectorized` is a function which \n",
            "returns ready-to-use token counts features instead of file names.\n",
            "\n",
            ".. _`20 newsgroups website`: http://people.csail.mit.edu/jrennie/20Newsgroups/\n",
            ".. _`TF-IDF`: https://en.wikipedia.org/wiki/Tf-idf\n",
            "\n",
            "\n",
            "Filtering text for more realistic training\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "It is easy for a classifier to overfit on particular things that appear in the\n",
            "20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very\n",
            "high F-scores, but their results would not generalize to other documents that\n",
            "aren't from this window of time.\n",
            "\n",
            "For example, let's look at the results of a multinomial Naive Bayes classifier,\n",
            "which is fast to train and achieves a decent F-score::\n",
            "\n",
            "  >>> from sklearn.naive_bayes import MultinomialNB\n",
            "  >>> from sklearn import metrics\n",
            "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
            "  ...                                      categories=categories)\n",
            "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
            "  >>> clf = MultinomialNB(alpha=.01)\n",
            "  >>> clf.fit(vectors, newsgroups_train.target)\n",
            "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "\n",
            "  >>> pred = clf.predict(vectors_test)\n",
            "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
            "  0.88213...\n",
            "\n",
            "(The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles\n",
            "the training and test data, instead of segmenting by time, and in that case\n",
            "multinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious\n",
            "yet of what's going on inside this classifier?)\n",
            "\n",
            "Let's take a look at what the most informative features are:\n",
            "\n",
            "  >>> import numpy as np\n",
            "  >>> def show_top10(classifier, vectorizer, categories):\n",
            "  ...     feature_names = np.asarray(vectorizer.get_feature_names())\n",
            "  ...     for i, category in enumerate(categories):\n",
            "  ...         top10 = np.argsort(classifier.coef_[i])[-10:]\n",
            "  ...         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
            "  ...\n",
            "  >>> show_top10(clf, vectorizer, newsgroups_train.target_names)\n",
            "  alt.atheism: edu it and in you that is of to the\n",
            "  comp.graphics: edu in graphics it is for and of to the\n",
            "  sci.space: edu it that is in and space to of the\n",
            "  talk.religion.misc: not it you in is that and to of the\n",
            "\n",
            "\n",
            "You can now see many things that these features have overfit to:\n",
            "\n",
            "- Almost every group is distinguished by whether headers such as\n",
            "  ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\n",
            "- Another significant feature involves whether the sender is affiliated with\n",
            "  a university, as indicated either by their headers or their signature.\n",
            "- The word \"article\" is a significant feature, based on how often people quote\n",
            "  previous posts like this: \"In article [article ID], [name] <[e-mail address]>\n",
            "  wrote:\"\n",
            "- Other features match the names and e-mail addresses of particular people who\n",
            "  were posting at the time.\n",
            "\n",
            "With such an abundance of clues that distinguish newsgroups, the classifiers\n",
            "barely have to identify topics from text at all, and they all perform at the\n",
            "same high level.\n",
            "\n",
            "For this reason, the functions that load 20 Newsgroups data provide a\n",
            "parameter called **remove**, telling it what kinds of information to strip out\n",
            "of each file. **remove** should be a tuple containing any subset of\n",
            "``('headers', 'footers', 'quotes')``, telling it to remove headers, signature\n",
            "blocks, and quotation blocks respectively.\n",
            "\n",
            "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
            "  ...                                      remove=('headers', 'footers', 'quotes'),\n",
            "  ...                                      categories=categories)\n",
            "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
            "  >>> pred = clf.predict(vectors_test)\n",
            "  >>> metrics.f1_score(pred, newsgroups_test.target, average='macro')\n",
            "  0.77310...\n",
            "\n",
            "This classifier lost over a lot of its F-score, just because we removed\n",
            "metadata that has little to do with topic classification.\n",
            "It loses even more if we also strip this metadata from the training data:\n",
            "\n",
            "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
            "  ...                                       remove=('headers', 'footers', 'quotes'),\n",
            "  ...                                       categories=categories)\n",
            "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
            "  >>> clf = MultinomialNB(alpha=.01)\n",
            "  >>> clf.fit(vectors, newsgroups_train.target)\n",
            "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "\n",
            "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
            "  >>> pred = clf.predict(vectors_test)\n",
            "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
            "  0.76995...\n",
            "\n",
            "Some other classifiers cope better with this harder version of the task. Try\n",
            "running :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py` with and without\n",
            "the ``--filter`` option to compare the results.\n",
            "\n",
            ".. topic:: Recommendation\n",
            "\n",
            "  When evaluating text classifiers on the 20 Newsgroups data, you\n",
            "  should strip newsgroup-related metadata. In scikit-learn, you can do this by\n",
            "  setting ``remove=('headers', 'footers', 'quotes')``. The F-score will be\n",
            "  lower because it is more realistic.\n",
            "\n",
            ".. topic:: Examples\n",
            "\n",
            "   * :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`\n",
            "\n",
            "   * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIszPnrBQqOe",
        "colab_type": "code",
        "outputId": "411033be-bcfd-48a3-d76e-d4268ad770e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "all_data['data'][:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"From: bbs.mirage@tsoft.net (Jerry Lee)\\nSubject: Cobra 2.0 1-b-1 Video card HELP ME!!!!\\nOrganization: The TSoft BBS and Public Access Unix, +1 415 969 8238\\nLines: 22\\n\\nDoes ANYONE out there in Net-land have any information on the Cobra 2.20 \\ncard?  The sticker on the end of the card reads\\n        Model: Cobra 1-B-1\\n        Bios:  Cobra v2.20\\n\\nI Havn't been able to find anything about it from anyone!  If you have \\nany information on how to get a hold of the company which produces the \\ncard or know where any drivers are for it, PLEASE let me know!\\n\\nAs far as I can tell, it's a CGA card that is taking up 2 of my 16-bit \\nISA slots but when I enable the test patterns, it displays much more than \\nthe usualy 4 CGA colors... At least 16 from what I can count.. Thanks!\\n\\n              .------------------------------------------.\\n              : Internet: jele@eis.calstate.edu          :\\n              :           bbs.mirage@gilligan.tsoft.net  :\\n              :           bbs.mirage@tsoft.sf-bay.org    :\\n              :           mirage@thetech.com             :\\n              : UUCP    : apple.com!tsoft!bbs.mirage     :\\n              `------------------------------------------'\\n \\n                    Computer and Video Imaging Major\\n\",\n",
              " 'From: zyeh@caspian.usc.edu (zhenghao yeh)\\nSubject: Ellipse Again\\nOrganization: University of Southern California, Los Angeles, CA\\nLines: 39\\nDistribution: world\\nNNTP-Posting-Host: caspian.usc.edu\\nKeywords: ellipse\\n\\n\\nHi! Everyone,\\n\\nBecause no one has touched the problem I posted last week, I guess\\nmy question was not so clear. Now I\\'d like to describe it in detail:\\n\\nThe offset of an ellipse is the locus of the center of a circle which\\nrolls on the ellipse. In other words, the distance between the ellipse\\nand its offset is same everywhere.\\n\\nThis problem comes from the geometric measurement when a probe is used.\\nThe tip of the probe is a ball and the computer just outputs the\\npositions of the ball\\'s center. Is the offset of an ellipse still\\nan ellipse? The answer is no! Ironically, DMIS - an American Indutrial\\nStandard says it is ellipse. So almost all the software which was\\nimplemented on the base of DMIS was wrong. The software was also sold\\ninternationaly. Imagine, how many people have or will suffer from this bug!!!\\nHow many qualified parts with ellipse were/will be discarded? And most\\nimportantly, how many defective parts with ellipse are/will be used?\\n\\nI was employed as a consultant by a company in Los Angeles last year\\nto specially solve this problem. I spent two months on analysis of this\\nproblem and six months on programming. Now my solution (nonlinear)\\nis not ideal because I can only reconstruct an ellipse from its entire\\nor half offset. It is very difficult to find the original ellipse from\\na quarter or a segment of its offset because the method I used is not\\nanalytical. I am now wondering if I didn\\'t touch the base and make things\\ncomplicated. Please give me a hint.\\n\\nI know you may argue this is not a CG problem. You are right, it is not.\\nHowever, so many people involved in the problem \"sphere from 4 poits\".\\nWhy not an ellipse? And why not its offset?\\n\\nPlease post here and let the others share our interests \\n(I got several emails from our netters, they said they need the\\nsummary of the answers).\\n\\nYeh\\nUSC\\n',\n",
              " \"From: lau@auriga.rose.brandeis.edu (frankie t. k. lau)\\nSubject: PC fastest line/circle drawing routines: HELP!\\nOrganization: Brandeis University\\nLines: 41\\n\\nhi all,\\n\\nIN SHORT: looking for very fast assembly code for line/circle drawing\\n\\t  on SVGA graphics.\\n\\nCOMPLETE:\\n\\tI am thinking of a simple but fast molecular\\ngraphics program to write on PC or clones. (ball-and-stick type)\\n\\nReasons: programs that I've seen are far too slow for this purpose.\\n\\nPlatform: 386/486 class machine.\\n\\t  800x600-16 or 1024x728-16 VGA graphics\\n\\t\\t(speed is important, 16-color for non-rendering\\n\\t\\t purpose is enough; may stay at 800x600 for\\n\\t\\t speed reason.)\\n         (hope the code would be generic enough for different SVGA\\n          cards.  My own card is based on Trident 8900c, not VESA?)\\n\\nWhat I'm looking for?\\n1) fast, very fast routines to draw lines/circles/simple-shapes\\n   on above-mentioned SVGA resolutions.\\n   Presumably in assembly languagine.\\n\\tYes, VERY FAST please.\\n2) related codes to help rotating/zooming/animating the drawings on screen.\\n   Drawings for beginning, would be lines, circles mainly, think of\\n   text, else later.\\n   (you know, the way molecular graphics rotates, zooms a molecule)\\n2) and any other codes (preferentially in C) that can help the \\n   project.\\n\\nFinal remarks;-\\nnon-profit.  expected to become share-, free-ware.\\n\\n\\tAny help is appreciated.\\n\\tthanks\\n\\n-Frankie\\nlau@tammy.harvard.edu\\n\\nPS pls also email, I may miss reply-post.\\n\",\n",
              " 'From: weilej@cary115.its.rpi.edu (Jason Lee Weiler)\\nSubject: Re: Sun IPX root window display - background picture\\nKeywords: sun ipx background picture\\nArticle-I.D.: rpi.gc15hqk\\nReply-To: weilej@rpi.edu\\nOrganization: Rensselaer Polytechnic Institute, Troy, NY.\\nLines: 31\\nNntp-Posting-Host: cary115.its.rpi.edu\\n\\nIn article <1993Apr19.220817.22480@osi.com>, scott@osi.com (Scott Fleming) writes:\\n|> \\n|> Hello netters!\\n|>  \\n|> I have a fairly weak question to ask everybody in netland.  I\\'ve looked though\\n|> the last FAQ for comp.graphics but I didn\\'t find my answer.  Thus the post.\\n|>  \\n|> I\\'ll keep it short.\\n|>  \\n|> QUESTION:  How do I display any raster files, gif files, iff or tiff images\\n|> that I have on my \"root window\" or background?  I have a sun ipc, openwindows\\n|> 3.0, Sun OS 4.1.3 if that helps any.\\n|>  \\n|> I\\'ve compiled POV for the sun and would like to display some of the work I have\\n|> done as a background/tile.  Thanks for any help or information that you\\n|> provide.  Have a good day.\\n|>  \\n|> Scott Fleming\\n|> OSI\\n|>  \\n|> P.S.\\n|> Kudo\\'s to the people who provided POV, its great!\\n|> \\n\\nScott,\\n\\tI\\'m not so sure if this is helpful, but I usually use XV v2.21.  I use Sun IPCs and IPXs, and it works fine.  It can display in a good number of ways.(root being one of them)  It\\'s also possible to have XV put up a background automatically at login.  Hope this helps.\\n\\nJason Weiler\\n<weilej@rpi.edu>\\n\\nBTW  XV v2.21 is on anonymous FTP somewhere. (archie fer it!)\\n',\n",
              " 'From: clldomps@cs.ruu.nl (Louis van Dompselaar)\\nSubject: Re: images of earth\\nOrganization: Utrecht University, Dept. of Computer Science\\nLines: 17\\n\\nIn <C5q0HK.KoD@hawnews.watson.ibm.com> ricky@watson.ibm.com (Rick Turner) writes:\\n\\n>Look in the /pub/SPACE directory on ames.arc.nasa.gov - there are a number\\n>of earth images there. You may have to hunt around the subdirectories as\\n>things tend to be filed under the mission (ie, \"APOLLO\") rather than under\\t\\n>the image subject.\\t\\n>\\nFor those of you who don\\'t need 24 bit, I got a 32 colour Amiga IFF\\nof a cloudless Earth (scanned). Looks okay when mapped on a sphere.\\nE-mail me and I\\'ll send it you...\\n\\nLouis\\n\\n-- \\nI\\'m hanging on your words, Living on your breath, Feeling with your skin,\\nWill I always be here?  -- In Your Room [ DM ]\\n\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEgWzXywQ2cq",
        "colab_type": "code",
        "outputId": "843dbc3f-8a1a-41ff-8649-c7301a739660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "source": [
        "print(all_data['data'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: bbs.mirage@tsoft.net (Jerry Lee)\n",
            "Subject: Cobra 2.0 1-b-1 Video card HELP ME!!!!\n",
            "Organization: The TSoft BBS and Public Access Unix, +1 415 969 8238\n",
            "Lines: 22\n",
            "\n",
            "Does ANYONE out there in Net-land have any information on the Cobra 2.20 \n",
            "card?  The sticker on the end of the card reads\n",
            "        Model: Cobra 1-B-1\n",
            "        Bios:  Cobra v2.20\n",
            "\n",
            "I Havn't been able to find anything about it from anyone!  If you have \n",
            "any information on how to get a hold of the company which produces the \n",
            "card or know where any drivers are for it, PLEASE let me know!\n",
            "\n",
            "As far as I can tell, it's a CGA card that is taking up 2 of my 16-bit \n",
            "ISA slots but when I enable the test patterns, it displays much more than \n",
            "the usualy 4 CGA colors... At least 16 from what I can count.. Thanks!\n",
            "\n",
            "              .------------------------------------------.\n",
            "              : Internet: jele@eis.calstate.edu          :\n",
            "              :           bbs.mirage@gilligan.tsoft.net  :\n",
            "              :           bbs.mirage@tsoft.sf-bay.org    :\n",
            "              :           mirage@thetech.com             :\n",
            "              : UUCP    : apple.com!tsoft!bbs.mirage     :\n",
            "              `------------------------------------------'\n",
            " \n",
            "                    Computer and Video Imaging Major\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUxKMdicQ99v",
        "colab_type": "code",
        "outputId": "cda2d546-d357-4908-bc36-c59f0cc444a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "all_data['target_names']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['comp.graphics']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQDsVFc-RKLW",
        "colab_type": "code",
        "outputId": "fab5814c-e029-41fc-838d-057088829a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "all_data['target'][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-CaR_roRTnF",
        "colab_type": "code",
        "outputId": "835318ed-35a6-4b96-8db6-d1c329acec5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "tfidf = TfidfVectorizer()\n",
        "tfidf.fit_transform(all_data['data']).toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.04, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.09, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       ...,\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
              "       [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, ..., 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-GziK_lRfzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}